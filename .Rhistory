# ESLI RUSSKIE BUKVI NE VIDNI --->
# File -- Reopen with encoding --- utf8 --- set as default --- ok
library("HSAUR") # из этого пакета возьмем набор данных по семиборью
library("dplyr") # манипуляции с данными
library("psych") # описательные статистики
library("lmtest") # тесты для линейных моделей
library("glmnet") # LASSO + ridge
library("ggplot2") # графики
library("car") # vif
df <-airqualiti
df <-airquality
head(df)
qplot(df, Solar.R, Temp)
qplot(data = df, Solar.R, Temp)
qplot(data = df, Ozone, Wind)
qplot(data = df, Ozone, Temp)
model <- lm(data = df, Ozone, Solar.R, Wind, Temp)
model <- lm(data = df, Ozone ~ Solar.R + Wind + Temp)
vif(model)
df2 <- na.omit(df)
h <- df2$Ozone
df2 <- select(df2, -Ozone)
df2 <- na.omit(df)
X0 <- model.matrix(data = df2, Ozone ~ 0 + Solar.R + Wind + Temp)
l <- seq(50,0.1,length=30)
m_lasso <- glmnet(X0, h, alpha=1, lambda=l)
coef(m_lasso)
coef(m_lasso, s = 1)
m_lasso <- glmnet(X0, h, alpha=0, lambda=l)
coef(m_lasso, s = 2)
round(1.57646889, 3)
m_lasso <- glmnet(X0, h, alpha=1, lambda=l)
plot(m_lasso,xvar="lambda")
X0
temp <- prcomp(X0, scale = T)
temp
h1 <- temp$x[,1]
h2 <- temp$x[,2]
h1 <- temp$x[,3]
h1 <- temp$x[,1]
h3 <- temp$x[,3]
qplot(h1,h2)
model <- lm(data = df, Ozone ~ Solar.R + Wind + Temp)
vif(model)
m_lasso <- glmnet(X0, h, alpha=0, lambda=l)
coef(m_lasso)
coef(m_lasso, s = 2)
m_lasso <- glmnet(X0, h, alpha=1, lambda=l)
plot(m_lasso,xvar="dev")
qplot(h1,h3)
library(ggplot2)
library(dplyr)
library(Ecdat)
download.packages("Ecdat")
install.packages("Ecdat")
library(Ecdat)
library(ggplot2)
library(dplyr)
library(Ecdat)
R.version
library(Imtest)
install.package("Imtest")
install.packages("Imtest")
install.packages("Imtest")
library(lmtest)
library(glmnet)
library(car)
data <- ChichWeight
data <- chickwts
glimpse(data)
df <- tbl_df(data)
library(ggplot2)
library(dplyr)
glimpse(data)
head(data)
data <- ChickWeight
head(data)
mean(data$weight, data$Time == 10)
data[Time == 10]
data(Time == 10)
data(data$Time == 10)
data[data$Time == 10]
data[data$Time == 10,2]
data[data$Time == 10,1]
mean(data[data$Time == 10,1])
mean(data[data$Time == 10,1])
table(data, mean(data[data$Time == 21,1])~Diet)
table(data)
table(data, Diet)
table(data, data$Diet)
table(data$Weight, data$Diet)
table(mean(data$Weight), data$Diet)
mean(data[data$Time == 21 && data$Time == 1, 1])
head(data)
mean(data[data$Time == 21 && data$Diet == 1, 1])
data[data$Time == 21 && data$Diet == 1, 1]
data[data$Time == 21 && data$Diet == 2, 1]
data
data[data$Time == 21 & data$Diet == 2, 1]
mean(data[data$Time == 21 & data$Diet == 1, 1])
mean(data[data$Time == 21 & data$Diet == 2, 1])
mean(data[data$Time == 21 & data$Diet == 3, 1])
mean(data[data$Time == 21 & data$Diet == 4, 1])
model <- lm(data, Weight~Time+Diet)
model <- lm(data = data, Weight~Time+Diet)
model <- lm(data = data, weight~Time+Diet)
model
summary(model)
data <- diamonds
qplot(data = diamonds, log(price),color=cut)+facet_grid(~cut)
model <- lm(data = data, price~carat+table+x+y+depth)
summary(model)
model <- lm(data = data, price~carat+table+x+y+z+depth)
summary(model)
model <- lm(data = data, price~carat+table+x+y+depth)
summary(model)
?diamonds
confint(model)
confint(model, level = 0.9)
library(Ecdat)
data("BudgetFood")
df <- data("BudgetFood")
head(df)
head(BudgetFood)
model <- lm(data=BudgetFood, wfood~totexp+size)
test <- c(700000, 4)
predict(model, newdata = test)
test <- data.frame(totexp = 700000, size = 4)
test
predict(model, newdata = test)
predict(model, newdata = test, interval = "confidence", level = 0.9)
resettest(model)
h <- na.omit(BudgetFood)
model1 <- lm(data = h, wfood~totexp+size)
model2 <- lm(data = h, wfood~totexp+size+sex)
waldtest(model1, model2)
summary(model1)
model2 <- lm(data = h, wfood~totexp:sex+size:sex+sex)
waldtest(model1, model2)
model2 <- lm(data = h, wfood~totexp:sex+size:sex)
waldtest(model1, model2)
model2 <- lm(data = h, wfood~totexp*sex+size*sex)
waldtest(model1, model2)
data <- mtcars
model <- lm(data = data, mpg ~ disp+hp+wt)
vif(model)
h <- select(data, - mpg)
glimpse(h)
h.pca <- prcomp(h, scale = T)
pcal <- h.pca$x[,1]
pcal
max(pcal)
summary(h.pca)
pca1 <- h.pca$x[,1]
pca1 <- h.pca$x[,1]
pca2 <- h.pca$x[,2]
pca3 <- h.pca$x[,3]
model1 <- lm(data = data, mpg~pca1+pca2)
model2 <- lm(data = data, mpg~pca1+pca2+pca3)
table(model1, model2)
mtable(model1, model2)
library(memisc)
mtable(model1, model2)
model1 <- lm(data = data, mpg~0+pca1+pca2)
model2 <- lm(data = data, mpg~0+pca1+pca2+pca3)
mtable(model1, model2)
model1 <- lm(data = data, mpg~pca1+pca2)
model2 <- lm(data = data, mpg~pca1+pca2+pca3)
mtable(model1, model2)
model1 <- lm(data$mpg~pca1+pca2)
model2 <- lm(data$mpg~pca1+pca2+pca3)
mtable(model1, model2)
model1 <- lm(data$mpg~0+pca1+pca2)
model2 <- lm(data$mpg~0+pca1+pca2+pca3)
mtable(model1, model2)
X0 <- model.matrix(data=MC, mpg~0+disp+hp+wt)
X0 <- model.matrix(data=data, mpg~0+disp+hp+wt)
model1 <- lm(data = X0, data$mpg~pca1+pca2)
h.pca <- prcomp(X0, scale = T)
pca1 <- h.pca$x[,1]
pca2 <- h.pca$x[,2]
pca3 <- h.pca$x[,3]
model1 <- lm(data = data, mpg~pca1+pca2)
model2 <- lm(data = data,mpg~pca1+pca2+pca3)
mtable(model1, model2)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x | f, layout = c(2, 1)) ## Plot with 2 panels
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
library(datasets)
data(airquality)
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x | f, layout = c(2, 1)) ## Plot with 2 panels
xyplot(y ~ x | f, layout = c(2, 1), axis <- c("asd","asda")) ## Plot with 2 panels
xyplot(y ~ x | f, layout = c(2, 1), axis = c("asd","asda")) ## Plot with 2 panels
?splom
?print.trellis
?trellis.par.set
?splom
library(Ecdat)
library(sandwich)
library(lmtest)
library(dplyr)
library(broom)
library(ggplot2)
Griliches
data <- Griliches
head(data)
?Griliches
model <- lm(data = data, lw80~age80+iq+school80+expr80)
vcov(model)
vcovHC(model)
vcovHC(model, type = "HC3")
m2 <- vcovHC(model, type = "HC3")
m1 <- vcovHC(model)
m1[3,5]
abs(m1[3,5]-m2[3,5])
m1 <- vcov(model)
abs(m1[3,5]-m2[3,5])
m1[3,5]
m1[3,2]
vcovHC(model, type = "HC0")[2,2]
vcovHC(model, type = "HC1")[2,2]
vcovHC(model, type = "HC2")[2,2]
vcovHC(model, type = "HC3")[2,2]
bptest(model)
bptest(model, data = data, varformula = ~expr80)
gqtest(model, order.by = age80, data = data, fraction = 0.4=2)
gqtest(model, order.by = age80, data = data, fraction = 0.2)
head(data)
gqtest(model, order.by = ~age80, data = data, fraction = 0.2)
library(lubridate)
library(sandwich)
library(lmtest)
library(car)
library(bstats)
library(devtools)
install_github(cran/bstats)
install_github("cran/bstats")
library(bstats)
library(zoo)
library(xts)
library(dplyr)
library(broom)
library(quantmod)
library(rusquant)
install_github("bdemeshev/rusquant")
library(rusquant)
install_github("bdemeshev/rusquant")
install_github("bdemeshev/sophisthse")
library(sophisthse)
library(Quandl)
data <- Solow
model <- lm(data = data, q~k+A)
m1 <- vcov(model)
m2 <- vcocHAC(model)
m2 <- vcovHAC(model)
m1
m1[2,2]-m2[2,2]
dwt(model)
model2 <- lm(q~k)
model2 <- lm(data = data, q~k)
bgtest(model2, order = 3)
Sys.setlocale("LC_TIME","C")
getSymbols(Symbols = "AAPL",from="2010-01-01", to="2014-02-03",src="google")
plot(AAPL$AAPL.Close, main = "")
Sys.setlocale("LC_TIME","C")
getSymbols(Symbols = "GOOG",from="2010-01-01", to="2014-02-03",src="google")
plot(GOOG$GOOG.Close, main = "")
Sys.setlocale("LC_TIME","C")
getSymbols(Symbols = "GOOG",from="2010-01-01", to="2014-02-03",src="google")
x <- GOOG$GOOG.Close
head(x)
model <- lm(data = x, GOOG.Close ~ lag(GOOG.Close,-1) + lag(GOOG.Close,-2))
lag(GOOG.GOOG.Close, -1)
lag(GOOG$GOOG.Close, -1)
model <- lm(data = x, GOOG.Close ~ lag(GOOG.Close,-1) + lag(GOOG.Close,-2))
lag(GOOG.Close, -1)
?lag
model <- lm(data = x, GOOG.Close ~ lag(GOOG.Close,1) + lag(GOOG.Close,2))
summary(model)
setwd("D:/Coursera/Reproducible Research/course project 1")
data <- read.csv('activity.csv')
head(data)
data <- read.csv('activity.csv')
library(dplyr)
df <- data %>%
group_by(date) %>%
summarize(sum(steps, na.rm = T))
df
library(ggplot2)
hist(x = df[,1], y = df[,2], data = df)
hist
?hist
hist(df)
qplot(data = df, geom = "histogram")
qplot(data = df, x = df$sum(steps, na.rm = T) geom = "histogram")
df <- data %>%
group_by(date) %>%
summarize(ttl_steps = sum(steps, na.rm = T))
head(df)
qplot(data = df, x = df$ttl_steps, geom = "histogram")
summary(df)
test <- summary(df)
test
test$ttl_steps
test.ttl_steps
test[,2]
test[3:4,2]
test[c(4,3),2]
hist(df$ttl_steps)
hist(df$ttl_steps, breaks = 20)
qplot(data = df, x = df$ttl_steps, geom = "histogram")
hist(df$ttl_steps, breaks = 20)
summary(df)[c(4,3),2]
